{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDbo9jUa4Ht4",
        "outputId": "3c3d9c41-a2e3-4ab8-fe38-25bce5b4575f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OhSVy6og3m3k",
        "outputId": "1b38e004-a152-4d47-8a6e-72d195afcce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LabelSense AI Food Label Analyzer\n",
            "=================================\n",
            "Upload a food label image to analyze:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b0753020-7bcb-4129-94c9-7a424545c895\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b0753020-7bcb-4129-94c9-7a424545c895\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving eggs1.jpg to eggs1.jpg\n",
            "Analyzing food label image in detail...\n",
            "\n",
            "===== LabelSense AI Detailed Analysis Results =====\n",
            "\n",
            "üìã EXTRACTED TEXT:\n",
            "----------------\n",
            "INGREDIENTS: Sour Cream (Cuttured Cream,\n",
            "Enzyme), Onions, Cream Cheese (Pasteurized\n",
            "Cultured Milk and Cream, Salt, Stabilizers\n",
            "[Kanthan, Carob Bean, and/or Guar Gums)),\n",
            "Canola Mayonnalse (Expeller Pressed Non\n",
            "GMO Canola Oil, Cage-Free Egg Yolks, Water,\n",
            "Honey, Distilled Vinegar, Cage-Free Whole\n",
            "Egg, Contains Less Than 2% of Salt, Spice,\n",
            "Lemon Juice Concentrate, Tocopherol *\n",
            "(Vitamin ¬£]), Oven Roasted Garlic Puree\n",
            "(Garlic, Water), Dehydrated Onion, Water, Saif,\n",
            "Vegetable Base (Saut√©ed Vegetables (Carrots,\n",
            "Celery, Onions, Tomato], Natural Sea Salt,\n",
            "Yeast Extract, Corn Oil, Vegetable Extracts),\n",
            "Expeller-Pressed Canola Oil, Sugar, Cuttured\n",
            "    \n",
            "   \n",
            "  \n",
            "  \n",
            "   \n",
            "  \n",
            "   \n",
            "  \n",
            "    \n",
            "  \n",
            "   \n",
            "  \n",
            "  \n",
            "   \n",
            "Nutrition Facts\n",
            "Serving Size 2 Tbsp (30g)\n",
            "Serving Pet Container about 8\n",
            "Amount Per Serving\n",
            "Calories 70__ Calories from Fat 60\n",
            "% Daily Value\"\n",
            "Total fat_6g 9%\n",
            "Saturated Fat 2.59 13%\n",
            "Cholesterol 15mg 5%\n",
            "Sodium 230mg 10%\n",
            "Total Carbohydrate 3g 1%\n",
            "    \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "    \n",
            "  \n",
            " \n",
            "  \n",
            "  \n",
            "  \n",
            " \n",
            " \n",
            "   \n",
            "  \n",
            "  \n",
            "   \n",
            "    \n",
            "  \n",
            " \n",
            " \n",
            " \n",
            "  \n",
            " \n",
            "‚Äî‚Äî‚Äî_‚Äî‚Äî‚Äî‚Äî_‚Äî_ |_ Dextrose {Cultured Dextrose, Maltodextrin),\n",
            "Dietary Fiber 0% | Batsamic Vinegar (Contains Sulfites [Naturally\n",
            "Sugars 1g Occurring)), Modified Corn Starch, Brown .\n",
            "   \n",
            "  \n",
            "Sugar, Lactic Acid, Spice,\n",
            "Contains Egg, Milk.\n",
            "IN\n",
            "Fresh Creative Foods, Vista, CA 92081\n",
            "_ r ~ -\n",
            "Protein 1g\n",
            "EE\n",
            "VitaminA 2% +Vitamin 2%\n",
            "Cakium 2% + Iron 0%\n",
            "Weta sonicant source of ans fat\n",
            "‚ÄúPesvent Daily Values are based on & 2,000 calovia\n",
            "det\n",
            "\n",
            "ü•ò INGREDIENTS DETECTED:\n",
            "---------------------\n",
            "1. sour cream __paren_0__\n",
            "2. cuttured cream\n",
            "3. enzyme\n",
            "4. pasteurized cultured milk and cream\n",
            "5. salt\n",
            "6. stabilizers [kanthan\n",
            "7. carob bean\n",
            "8. and/or guar gums\n",
            "9. expeller pressed non gmo canola oil\n",
            "10. cage-free egg yolks\n",
            "11. water\n",
            "12. honey\n",
            "13. distilled vinegar\n",
            "14. cage-free whole egg\n",
            "15. contains less than 2% of salt\n",
            "16. spice\n",
            "17. lemon juice concentrate\n",
            "18. tocopherol\n",
            "19. (vitamin ¬£]\n",
            "20. garlic\n",
            "21. saut√©ed vegetables (carrots\n",
            "22. celery\n",
            "23. onions\n",
            "24. tomato]\n",
            "25. natural sea salt\n",
            "26. yeast extract\n",
            "27. corn oil\n",
            "28. vegetable extracts\n",
            "29. 30g\n",
            "30. onions\n",
            "31. cream cheese __paren_1__)\n",
            "32. canola mayonnalse __paren_2__\n",
            "33. oven roasted garlic puree __paren_3__\n",
            "34. dehydrated onion\n",
            "35. water\n",
            "36. saif\n",
            "37. vegetable base __paren_4__\n",
            "38. expeller-pressed canola oil\n",
            "39. sugar\n",
            "40. cuttured nutrition facts serving size 2 tbsp __paren_5__ serving pet container about 8 amount per serving calories 70__ calories from fat 60 % daily value\" total fat_6g 9% saturated fat 2\n",
            "\n",
            "üå± DIETARY ANALYSIS:\n",
            "-----------------\n",
            "Vegan Status: ‚ùå Not suitable for vegans\n",
            "Non-Vegan Ingredients:\n",
            "- sour cream __paren_0__\n",
            "- cuttured cream\n",
            "- pasteurized cultured milk and cream\n",
            "- cage-free egg yolks\n",
            "- honey\n",
            "- cage-free whole egg\n",
            "- cream cheese __paren_1__)\n",
            "\n",
            "Vegetarian Status: ‚úÖ Suitable for vegetarians\n",
            "\n",
            "‚ö†Ô∏è ALLERGEN INFORMATION:\n",
            "----------------------\n",
            "Allergens Found: ‚ö†Ô∏è Yes\n",
            "Potential Allergens:\n",
            "- pasteurized cultured milk and cream\n",
            "- cage-free egg yolks\n",
            "- cage-free whole egg\n",
            "- celery\n",
            "\n",
            "üîç ADDITIONAL INFORMATION:\n",
            "------------------------\n",
            "This analysis is based on automated OCR and should not replace reading the actual label.\n",
            "If you have allergies or dietary restrictions, please consult the original packaging.\n"
          ]
        }
      ],
      "source": [
        "# LabelSense: AI-Driven Food Label Analyzer\n",
        "# An NLP Class Project Implementation\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "import warnings\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import files\n",
        "\n",
        "# Install tesseract in Colab environment\n",
        "if 'google.colab' in sys.modules:\n",
        "    import subprocess\n",
        "    subprocess.run([\"apt-get\", \"update\"], check=True)\n",
        "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"tesseract-ocr\"], check=True)\n",
        "    subprocess.run([\"pip\", \"install\", \"pytesseract\"], check=True)\n",
        "    # Set path for Colab\n",
        "    pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
        "else:\n",
        "    # Set path for local Windows environment\n",
        "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "except:\n",
        "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"], check=True)\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Constants\n",
        "ALLERGENS = [\n",
        "    'milk', 'dairy', 'eggs', 'egg', 'peanuts', 'peanut', 'tree nuts', 'almond', 'almonds', 'walnut', 'walnuts',\n",
        "    'cashew', 'cashews', 'hazelnut', 'hazelnuts', 'shellfish', 'fish', 'wheat', 'gluten', 'soy', 'soya',\n",
        "    'sesame', 'mustard', 'celery', 'lupin', 'sulphites', 'sulfites', 'molluscs', 'mollusks'\n",
        "]\n",
        "\n",
        "NON_VEGAN = [\n",
        "    'milk', 'dairy', 'cheese', 'eggs', 'egg', 'honey', 'meat', 'beef', 'pork', 'chicken', 'turkey', 'lamb',\n",
        "    'gelatin', 'gelatine', 'lard', 'tallow', 'whey', 'casein', 'lactose', 'rennet', 'shellac', 'carmine',\n",
        "    'isinglass', 'albumin', 'cochineal', 'fish', 'shellfish', 'beef fat', 'butter', 'buttermilk', 'yogurt',\n",
        "    'cream', 'mayonnaise', 'bacon', 'duck', 'goose'\n",
        "]\n",
        "\n",
        "NON_VEGETARIAN = [\n",
        "    'meat', 'beef', 'pork', 'chicken', 'turkey', 'lamb', 'gelatin', 'gelatine', 'lard', 'tallow', 'rennet',\n",
        "    'shellac', 'isinglass', 'carmine', 'cochineal', 'fish', 'shellfish', 'beef fat', 'bacon', 'duck', 'goose'\n",
        "]\n",
        "\n",
        "# Class to handle image preprocessing\n",
        "class ImagePreprocessor:\n",
        "    @staticmethod\n",
        "    def resize_image(image, width=800):\n",
        "        \"\"\"Resize image while maintaining aspect ratio\"\"\"\n",
        "        h, w = image.shape[:2]\n",
        "        ratio = width / w\n",
        "        dim = (width, int(h * ratio))\n",
        "        return cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    @staticmethod\n",
        "    def denoise_image(image):\n",
        "        \"\"\"Apply denoising to the image\"\"\"\n",
        "        return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_thresholding(image):\n",
        "        \"\"\"Apply thresholding to prepare for OCR\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        return cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_orientation(image):\n",
        "        \"\"\"Detect and correct image orientation\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        # Use Tesseract OSD to detect orientation\n",
        "        osd = pytesseract.image_to_osd(gray)\n",
        "        angle = int(re.search(r'(?<=Rotate: )\\d+', osd).group())\n",
        "\n",
        "        if angle != 0:\n",
        "            (h, w) = image.shape[:2]\n",
        "            center = (w // 2, h // 2)\n",
        "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "            image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC,\n",
        "                                   borderMode=cv2.BORDER_REPLICATE)\n",
        "        return image\n",
        "\n",
        "    @staticmethod\n",
        "    def enhance_contrast(image):\n",
        "        \"\"\"Enhance contrast using CLAHE\"\"\"\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "        cl = clahe.apply(l)\n",
        "        limg = cv2.merge((cl, a, b))\n",
        "        return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(image):\n",
        "        \"\"\"Apply full preprocessing pipeline\"\"\"\n",
        "        if image is None:\n",
        "            raise ValueError(\"Image not loaded properly\")\n",
        "\n",
        "        try:\n",
        "            # Apply preprocessing steps\n",
        "            image = ImagePreprocessor.resize_image(image)\n",
        "            image = ImagePreprocessor.denoise_image(image)\n",
        "            image = ImagePreprocessor.enhance_contrast(image)\n",
        "\n",
        "            # Try to detect and correct orientation\n",
        "            try:\n",
        "                image = ImagePreprocessor.detect_orientation(image)\n",
        "            except:\n",
        "                pass  # Skip if orientation detection fails\n",
        "\n",
        "            # Create a binary version for OCR\n",
        "            binary = ImagePreprocessor.apply_thresholding(image)\n",
        "\n",
        "            return image, binary\n",
        "        except Exception as e:\n",
        "            print(f\"Error in preprocessing: {str(e)}\")\n",
        "            return image, None\n",
        "\n",
        "# Class to handle OCR operations\n",
        "class OCREngine:\n",
        "    @staticmethod\n",
        "    def extract_text(image):\n",
        "        \"\"\"Extract text from the image using Tesseract OCR\"\"\"\n",
        "        try:\n",
        "            # Extract using PSM 4 (assume a single column of text)\n",
        "            text = pytesseract.image_to_string(image, config='--psm 4')\n",
        "\n",
        "            # If little text is found, try different PSM modes\n",
        "            if len(text) < 50:\n",
        "                # Try different PSM modes to get the best results\n",
        "                text_psm_6 = pytesseract.image_to_string(image, config='--psm 6')\n",
        "                text_psm_11 = pytesseract.image_to_string(image, config='--psm 11')\n",
        "                text_psm_3 = pytesseract.image_to_string(image, config='--psm 3')\n",
        "\n",
        "                # Use the one with most text\n",
        "                candidates = [text, text_psm_3, text_psm_6, text_psm_11]\n",
        "                text = max(candidates, key=len)\n",
        "\n",
        "            # Clean up the extracted text\n",
        "            text = text.replace('\\n\\n', '\\n').strip()\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"OCR error: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_ingredients_section(text):\n",
        "        \"\"\"Extract the ingredients section from the OCR text\"\"\"\n",
        "        # Various ways ingredients sections are labeled\n",
        "        patterns = [\n",
        "            r'(?i)ingredients\\s*:(.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)ingredients\\s*list\\s*:(.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)contains\\s*:(.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)ingred(?:i|l)ents\\s*:(.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)ingredients?[\\s\\.\\)](.+?)(?:\\.|$|\\n\\n|\\*{3})',\n",
        "            r'(?i)ingredients(.+?)(?=allerg[ye]|$|\\n\\n|\\*{3})'\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, text, re.DOTALL)\n",
        "            if match:\n",
        "                ingredients_text = match.group(1).strip()\n",
        "                if len(ingredients_text) > 20:  # Only return if we got a substantial match\n",
        "                    return ingredients_text\n",
        "\n",
        "        # If the text is short, it might be just the ingredients section itself\n",
        "        if len(text) < 1000 and ',' in text:\n",
        "            return text\n",
        "\n",
        "        # If no specific ingredients section is found, check if the whole text contains common ingredients\n",
        "        words = text.lower().split()\n",
        "        ingredient_markers = ['sugar', 'salt', 'flour', 'milk', 'butter', 'egg', 'oil']\n",
        "        if any(marker in words for marker in ingredient_markers):\n",
        "            return text\n",
        "\n",
        "        return text\n",
        "\n",
        "# Class to analyze ingredients\n",
        "class IngredientAnalyzer:\n",
        "    def __init__(self):\n",
        "        # Initialize ingredient database with Open Food Facts data\n",
        "        # In a real implementation, you would load this data from a database\n",
        "        self.ingredient_database = {\n",
        "            # Common ingredients and their properties\n",
        "            # Format: 'ingredient': {'vegan': bool, 'vegetarian': bool, 'allergen': bool}\n",
        "        }\n",
        "\n",
        "        # Load pre-defined lists\n",
        "        self.allergens = set(ALLERGENS)\n",
        "        self.non_vegan = set(NON_VEGAN)\n",
        "        self.non_vegetarian = set(NON_VEGETARIAN)\n",
        "\n",
        "        # Add cake-specific ingredients to the lists\n",
        "        self.allergens.update(['wheat', 'soya', 'sulphur dioxide', 'sulphites', 'sulfites'])\n",
        "        self.non_vegan.update(['milk powder', 'skimmed milk powder', 'milk powder', 'belgian chocolate', 'cocoa butter'])\n",
        "\n",
        "    def parse_ingredients(self, ingredients_text):\n",
        "        \"\"\"Parse the ingredients text into a list of individual ingredients\"\"\"\n",
        "        if not ingredients_text:\n",
        "            return []\n",
        "\n",
        "        # Clean up formatting\n",
        "        text = re.sub(r'\\s+', ' ', ingredients_text)\n",
        "\n",
        "        # Try to split by common separators while preserving parenthetical content\n",
        "        # First, extract all text in parentheses and replace with placeholders\n",
        "        parenthesis_contents = []\n",
        "        def replace_parens(match):\n",
        "            parenthesis_contents.append(match.group(1))\n",
        "            return f\"__PAREN_{len(parenthesis_contents)-1}__\"\n",
        "\n",
        "        # Replace parentheses content with placeholders\n",
        "        processed_text = re.sub(r'\\(([^)]+)\\)', replace_parens, text)\n",
        "\n",
        "        # Split by commas and other separators\n",
        "        raw_ingredients = re.split(r',|\\*|‚Ä¢|;', processed_text)\n",
        "        ingredients = []\n",
        "\n",
        "        # Process each raw ingredient\n",
        "        for raw in raw_ingredients:\n",
        "            raw = raw.strip().lower()\n",
        "            if not raw:\n",
        "                continue\n",
        "\n",
        "            # Replace parenthesis placeholders with original content\n",
        "            while '__PAREN_' in raw:\n",
        "                match = re.search(r'__PAREN_(\\d+)__', raw)\n",
        "                if match:\n",
        "                    idx = int(match.group(1))\n",
        "                    if idx < len(parenthesis_contents):\n",
        "                        raw = raw.replace(f\"__PAREN_{idx}__\", f\"({parenthesis_contents[idx]})\")\n",
        "\n",
        "            ingredients.append(raw)\n",
        "\n",
        "            # Also add the parenthetical parts as separate ingredients\n",
        "            for paren_content in parenthesis_contents:\n",
        "                sub_ingredients = re.split(r',|\\*|‚Ä¢|;', paren_content)\n",
        "                for sub in sub_ingredients:\n",
        "                    sub = sub.strip().lower()\n",
        "                    if sub and len(sub) > 2 and sub not in ingredients:\n",
        "                        ingredients.append(sub)\n",
        "\n",
        "        return ingredients\n",
        "\n",
        "    def is_vegan(self, ingredients):\n",
        "        \"\"\"Check if the ingredient list is vegan\"\"\"\n",
        "        if not ingredients:\n",
        "            return {\"is_vegan\": False, \"non_vegan_ingredients\": [\"Unknown ingredients\"]}\n",
        "\n",
        "        non_vegan_ingredients = []\n",
        "\n",
        "        for ingredient in ingredients:\n",
        "            # Check against non-vegan items\n",
        "            for non_vegan_item in self.non_vegan:\n",
        "                if non_vegan_item in ingredient.lower():\n",
        "                    non_vegan_ingredients.append(ingredient)\n",
        "                    break\n",
        "\n",
        "        return {\n",
        "            \"is_vegan\": len(non_vegan_ingredients) == 0,\n",
        "            \"non_vegan_ingredients\": non_vegan_ingredients\n",
        "        }\n",
        "\n",
        "    def is_vegetarian(self, ingredients):\n",
        "        \"\"\"Check if the ingredient list is vegetarian\"\"\"\n",
        "        if not ingredients:\n",
        "            return {\"is_vegetarian\": False, \"non_vegetarian_ingredients\": [\"Unknown ingredients\"]}\n",
        "\n",
        "        non_vegetarian_ingredients = []\n",
        "\n",
        "        for ingredient in ingredients:\n",
        "            # Check against non-vegetarian items\n",
        "            for non_veg_item in self.non_vegetarian:\n",
        "                if non_veg_item in ingredient.lower():\n",
        "                    non_vegetarian_ingredients.append(ingredient)\n",
        "                    break\n",
        "\n",
        "        return {\n",
        "            \"is_vegetarian\": len(non_vegetarian_ingredients) == 0,\n",
        "            \"non_vegetarian_ingredients\": non_vegetarian_ingredients\n",
        "        }\n",
        "\n",
        "    def find_allergens(self, ingredients):\n",
        "        \"\"\"Identify potential allergens in the ingredient list\"\"\"\n",
        "        if not ingredients:\n",
        "            return {\"allergens_found\": False, \"allergens\": []}\n",
        "\n",
        "        allergens_found = []\n",
        "\n",
        "        for ingredient in ingredients:\n",
        "            # Check against allergens list\n",
        "            for allergen in self.allergens:\n",
        "                if allergen in ingredient.lower():\n",
        "                    allergens_found.append(ingredient)\n",
        "                    break\n",
        "\n",
        "        return {\n",
        "            \"allergens_found\": len(allergens_found) > 0,\n",
        "            \"allergens\": allergens_found\n",
        "        }\n",
        "\n",
        "    def explain_ingredient(self, ingredient):\n",
        "        \"\"\"Provide a simple explanation of an ingredient\"\"\"\n",
        "        # This would ideally use a database or API to look up ingredients\n",
        "        # For demonstration, we'll return a simple placeholder\n",
        "        return f\"Definition of {ingredient}: This is a placeholder explanation. In a real implementation, this would provide detailed information about the ingredient.\"\n",
        "\n",
        "# Class to handle the complete analysis process\n",
        "class LabelSense:\n",
        "    def __init__(self):\n",
        "        self.preprocessor = ImagePreprocessor()\n",
        "        self.ocr_engine = OCREngine()\n",
        "        self.analyzer = IngredientAnalyzer()\n",
        "\n",
        "    def analyze_label(self, image_path):\n",
        "        \"\"\"Analyze a food label image\"\"\"\n",
        "        # Load the image\n",
        "        try:\n",
        "            if isinstance(image_path, str):\n",
        "                image = cv2.imread(image_path)\n",
        "            else:\n",
        "                # Assume it's already a numpy array\n",
        "                image = image_path\n",
        "\n",
        "            if image is None:\n",
        "                return {\"error\": \"Could not load image\"}\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Error loading image: {str(e)}\"}\n",
        "\n",
        "        # Preprocess the image\n",
        "        try:\n",
        "            processed_image, binary_image = self.preprocessor.preprocess(image)\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Error preprocessing image: {str(e)}\"}\n",
        "\n",
        "        # Extract text using OCR\n",
        "        try:\n",
        "            if binary_image is not None:\n",
        "                text = self.ocr_engine.extract_text(binary_image)\n",
        "            else:\n",
        "                text = self.ocr_engine.extract_text(processed_image)\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"OCR error: {str(e)}\"}\n",
        "\n",
        "        # Extract ingredients section\n",
        "        ingredients_text = self.ocr_engine.extract_ingredients_section(text)\n",
        "\n",
        "        # Parse ingredients\n",
        "        ingredients = self.analyzer.parse_ingredients(ingredients_text)\n",
        "\n",
        "        # Analyze ingredients\n",
        "        vegan_results = self.analyzer.is_vegan(ingredients)\n",
        "        vegetarian_results = self.analyzer.is_vegetarian(ingredients)\n",
        "        allergen_results = self.analyzer.find_allergens(ingredients)\n",
        "\n",
        "        # Compile results\n",
        "        results = {\n",
        "            \"ingredients_detected\": ingredients,\n",
        "            \"vegan_analysis\": vegan_results,\n",
        "            \"vegetarian_analysis\": vegetarian_results,\n",
        "            \"allergen_analysis\": allergen_results,\n",
        "            \"full_text\": text\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "# Function to download a sample image for testing\n",
        "def download_sample_image():\n",
        "    \"\"\"Download a sample food label image for testing\"\"\"\n",
        "    # Updated URL to a more reliable source\n",
        "    url = \"https://raw.githubusercontent.com/open-mmlab/mmocr/main/demo/demo_text_ocr.jpg\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(\"sample_label.jpg\", \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        return \"sample_label.jpg\"\n",
        "    else:\n",
        "        print(\"Failed to download sample image\")\n",
        "        return None\n",
        "\n",
        "# Main function to demonstrate the LabelSense system\n",
        "def main():\n",
        "    # Initialize LabelSense\n",
        "    label_sense = LabelSense()\n",
        "\n",
        "    # Download a sample image\n",
        "    print(\"Downloading a sample food label image...\")\n",
        "    sample_image_path = download_sample_image()\n",
        "\n",
        "    if sample_image_path:\n",
        "        print(f\"Sample image downloaded as {sample_image_path}\")\n",
        "\n",
        "        # Analyze the label\n",
        "        print(\"Analyzing food label...\")\n",
        "        results = label_sense.analyze_label(sample_image_path)\n",
        "\n",
        "        # Display results\n",
        "        print(\"\\n===== LabelSense Analysis Results =====\")\n",
        "\n",
        "        if \"error\" in results:\n",
        "            print(f\"Error: {results['error']}\")\n",
        "        else:\n",
        "            print(\"\\nIngredients Detected:\")\n",
        "            for ingredient in results[\"ingredients_detected\"]:\n",
        "                print(f\"- {ingredient}\")\n",
        "\n",
        "            print(\"\\nVegan Analysis:\")\n",
        "            print(f\"Is Vegan: {results['vegan_analysis']['is_vegan']}\")\n",
        "            if not results['vegan_analysis']['is_vegan']:\n",
        "                print(\"Non-Vegan Ingredients:\")\n",
        "                for ingredient in results['vegan_analysis']['non_vegan_ingredients']:\n",
        "                    print(f\"- {ingredient}\")\n",
        "\n",
        "            print(\"\\nVegetarian Analysis:\")\n",
        "            print(f\"Is Vegetarian: {results['vegetarian_analysis']['is_vegetarian']}\")\n",
        "            if not results['vegetarian_analysis']['is_vegetarian']:\n",
        "                print(\"Non-Vegetarian Ingredients:\")\n",
        "                for ingredient in results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "                    print(f\"- {ingredient}\")\n",
        "\n",
        "            print(\"\\nAllergen Analysis:\")\n",
        "            print(f\"Allergens Found: {results['allergen_analysis']['allergens_found']}\")\n",
        "            if results['allergen_analysis']['allergens_found']:\n",
        "                print(\"Allergens:\")\n",
        "                for allergen in results['allergen_analysis']['allergens']:\n",
        "                    print(f\"- {allergen}\")\n",
        "    else:\n",
        "        print(\"Could not download sample image. Please provide your own image path.\")\n",
        "\n",
        "# Example of running the analysis on a local image\n",
        "def analyze_local_image(image_path):\n",
        "    # Initialize LabelSense\n",
        "    label_sense = LabelSense()\n",
        "\n",
        "    # Analyze the label\n",
        "    print(f\"Analyzing food label from {image_path}...\")\n",
        "    results = label_sense.analyze_label(image_path)\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\n===== LabelSense Analysis Results =====\")\n",
        "\n",
        "    if \"error\" in results:\n",
        "        print(f\"Error: {results['error']}\")\n",
        "    else:\n",
        "        print(\"\\nIngredients Detected:\")\n",
        "        for ingredient in results[\"ingredients_detected\"]:\n",
        "            print(f\"- {ingredient}\")\n",
        "\n",
        "        print(\"\\nVegan Analysis:\")\n",
        "        print(f\"Is Vegan: {results['vegan_analysis']['is_vegan']}\")\n",
        "        if not results['vegan_analysis']['is_vegan']:\n",
        "            print(\"Non-Vegan Ingredients:\")\n",
        "            for ingredient in results['vegan_analysis']['non_vegan_ingredients']:\n",
        "                print(f\"- {ingredient}\")\n",
        "\n",
        "        print(\"\\nVegetarian Analysis:\")\n",
        "        print(f\"Is Vegetarian: {results['vegetarian_analysis']['is_vegetarian']}\")\n",
        "        if not results['vegetarian_analysis']['is_vegetarian']:\n",
        "            print(\"Non-Vegetarian Ingredients:\")\n",
        "            for ingredient in results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "                print(f\"- {ingredient}\")\n",
        "\n",
        "        print(\"\\nAllergen Analysis:\")\n",
        "        print(f\"Allergens Found: {results['allergen_analysis']['allergens_found']}\")\n",
        "        if results['allergen_analysis']['allergens_found']:\n",
        "            print(\"Allergens:\")\n",
        "            for allergen in results['allergen_analysis']['allergens']:\n",
        "                print(f\"- {allergen}\")\n",
        "\n",
        "# Advanced functionality: Train a custom model for ingredient detection\n",
        "def train_ingredient_detection_model():\n",
        "    \"\"\"Train a custom model to detect ingredients from label images\"\"\"\n",
        "    # This is a placeholder for a real training function\n",
        "    # In an actual implementation, this would:\n",
        "    # 1. Load a dataset of food label images with annotated ingredient lists\n",
        "    # 2. Extract features using computer vision techniques\n",
        "    # 3. Train a neural network to identify ingredients\n",
        "\n",
        "    # Example neural network architecture (not functional without proper dataset)\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')  # Number of classes would depend on the task\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"Model architecture defined for ingredient detection.\")\n",
        "    print(\"Note: This is a placeholder. Actual training requires a dataset.\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to build an ingredient database from Open Food Facts\n",
        "def build_ingredient_database():\n",
        "    \"\"\"Build an ingredient database from Open Food Facts data\"\"\"\n",
        "    # In a real implementation, you would:\n",
        "    # 1. Download the Open Food Facts data dump\n",
        "    # 2. Extract ingredient information\n",
        "    # 3. Build a database of ingredients with properties\n",
        "\n",
        "    print(\"Building ingredient database from Open Food Facts...\")\n",
        "    print(\"Note: This is a placeholder. Actual database building requires downloading and processing the Open Food Facts dataset.\")\n",
        "\n",
        "    # Example of how you would process the data\n",
        "    database = {}\n",
        "\n",
        "    # Placeholder for a few sample entries\n",
        "    database['sugar'] = {'vegan': True, 'vegetarian': True, 'allergen': False}\n",
        "    database['milk'] = {'vegan': False, 'vegetarian': True, 'allergen': True}\n",
        "    database['beef'] = {'vegan': False, 'vegetarian': False, 'allergen': False}\n",
        "\n",
        "    print(f\"Created a sample database with {len(database)} entries.\")\n",
        "    return database\n",
        "\n",
        "def analyze_label_image(image_file):\n",
        "    \"\"\"Create a detailed analysis of the uploaded image\"\"\"\n",
        "    # Initialize LabelSense\n",
        "    label_sense = LabelSense()\n",
        "\n",
        "    # Analyze the label\n",
        "    print(f\"Analyzing food label image in detail...\")\n",
        "    results = label_sense.analyze_label(image_file)\n",
        "\n",
        "    # Display results with more detailed information\n",
        "    print(\"\\n===== LabelSense AI Detailed Analysis Results =====\")\n",
        "\n",
        "    if \"error\" in results:\n",
        "        print(f\"Error: {results['error']}\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüìã EXTRACTED TEXT:\")\n",
        "    print(\"----------------\")\n",
        "    print(results[\"full_text\"])\n",
        "\n",
        "    print(\"\\nü•ò INGREDIENTS DETECTED:\")\n",
        "    print(\"---------------------\")\n",
        "    if results[\"ingredients_detected\"]:\n",
        "        for i, ingredient in enumerate(results[\"ingredients_detected\"], 1):\n",
        "            print(f\"{i}. {ingredient}\")\n",
        "    else:\n",
        "        print(\"No specific ingredients could be detected with confidence.\")\n",
        "\n",
        "    print(\"\\nüå± DIETARY ANALYSIS:\")\n",
        "    print(\"-----------------\")\n",
        "    print(f\"Vegan Status: {'‚úÖ Suitable' if results['vegan_analysis']['is_vegan'] else '‚ùå Not suitable'} for vegans\")\n",
        "    if not results['vegan_analysis']['is_vegan'] and results['vegan_analysis']['non_vegan_ingredients']:\n",
        "        print(\"Non-Vegan Ingredients:\")\n",
        "        for ingredient in results['vegan_analysis']['non_vegan_ingredients']:\n",
        "            print(f\"- {ingredient}\")\n",
        "\n",
        "    print(f\"\\nVegetarian Status: {'‚úÖ Suitable' if results['vegetarian_analysis']['is_vegetarian'] else '‚ùå Not suitable'} for vegetarians\")\n",
        "    if not results['vegetarian_analysis']['is_vegetarian'] and results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "        print(\"Non-Vegetarian Ingredients:\")\n",
        "        for ingredient in results['vegetarian_analysis']['non_vegetarian_ingredients']:\n",
        "            print(f\"- {ingredient}\")\n",
        "\n",
        "    print(\"\\n‚ö†Ô∏è ALLERGEN INFORMATION:\")\n",
        "    print(\"----------------------\")\n",
        "    print(f\"Allergens Found: {'‚ö†Ô∏è Yes' if results['allergen_analysis']['allergens_found'] else '‚úÖ None detected'}\")\n",
        "    if results['allergen_analysis']['allergens_found']:\n",
        "        print(\"Potential Allergens:\")\n",
        "        for allergen in results['allergen_analysis']['allergens']:\n",
        "            print(f\"- {allergen}\")\n",
        "\n",
        "    print(\"\\nüîç ADDITIONAL INFORMATION:\")\n",
        "    print(\"------------------------\")\n",
        "    print(\"This analysis is based on automated OCR and should not replace reading the actual label.\")\n",
        "    print(\"If you have allergies or dietary restrictions, please consult the original packaging.\")\n",
        "\n",
        "# Main execution block at the end\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"LabelSense AI Food Label Analyzer\")\n",
        "    print(\"=================================\")\n",
        "\n",
        "    if 'google.colab' in sys.modules:\n",
        "        print(\"Upload a food label image to analyze:\")\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            image_path = list(uploaded.keys())[0]\n",
        "            analyze_label_image(image_path)\n",
        "    else:\n",
        "        # Option 1: Run with sample image download\n",
        "        main()\n",
        "\n",
        "        # Option 2: Run with your own image (replace with your image path)\n",
        "        # my_image_path = \"path/to/your/food_label.jpg\"  # Change this to your image path\n",
        "        # analyze_local_image(my_image_path)"
      ]
    }
  ]
}